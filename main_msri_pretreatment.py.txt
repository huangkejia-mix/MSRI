from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
from scipy.spatial.transform import Rotation as Rot
import numpy as np
import random
import time

import open3d as o3d
import laspy




# -*- coding: utf-8 -*-
"""3DSSF_Task_III.ipynb

# pip
# install
# open3d == 0.12
# .0
#
# !pip
# install
# chart_studio

import chart_studio.plotly as py
import plotly.graph_objs as go

import numpy as np
import open3d as o3d
import copy
import time
import pandas as pd

import os
import laspy

from sklearn.neighbors import NearestNeighbors
# from open3d.j_visualizer import JVisualizer
# from google.colab import output
# output.enable_custom_widget_manager()
# from google.colab import drive

from scipy.spatial import cKDTree as KDTree

# drive.mount('/content/drive')

ply_a = '/content/drive/MyDrive/fountain_a.ply'
ply_b = '/content/drive/MyDrive/fountain_b.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/bunny_part1.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/bunny_part2.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/01-room_source.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/01-room_target.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/dragon3 - Cloud-other.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/dragon3 - Cloud.ply'

# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/444.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/555.ply'

# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/las-aftercolor-555.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/las-aftercolor-444-withoutcolor-ver2.ply'

# 重要的典型使用场景-树木和建筑物和道路
ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/las-aftercolor-777777-3 - Cloud - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/las-aftercolor-777777-2 - Cloud - Cloud.ply'

# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-16-59-324 - Cloud-222.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-16-33-559 - Cloud-222.ply'

# 重要的典型使用场景-老北区操场附近区域-华测(处理后)同一批次点云成果
ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-17-26-341 - Cloud-clip.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-16-59-324 - Cloud-clip.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-12-32-05-599 - Cloud2 - Cloud - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-12-33-40-531 - Cloud2 - Cloud - Cloud.ply'


ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/dragon3 - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/dragon3 - Cloud-other.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/dragon3 - Cloud - Cloud333.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/dragon3 - Cloud - Cloud222.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/bunny_part1.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/bunny_part2.ply'

# # 北区操场附近的足球场
# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-16-59-324 - Cloud-clip222.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-17-26-341 - Cloud-clip222.ply'
# 新北教学楼附近的大楼
ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-12-33-40-531 - Cloud-clip - Cloud - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-12-32-05-599 - Cloud-clip - Cloud - Cloud.ply'
#
#
# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-02-27-342 - Cloud - Cloud.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/202278_03_51_52_000-13-01-45-270 - Cloud - Cloud.ply'


# 南方数据
# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_070737_0002 - Cloud - Cloud.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_071029_0000 - Cloud - Cloud.ply'
#
# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0007 - Cloud222.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_080436_0000 - Cloud222.ply'
#
# 这份数据的速度和精度, 明显比sota超过多倍
ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0006 - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0005 - Cloud.ply'


# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_081959_0011 - Cloud222 - Cloud.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_081959_0012 - Cloud222 - Cloud.ply'
ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_081959_0011 - Cloud - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_081959_0012 - Cloud - Cloud.ply'


ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0007 - Cloud - Cloud222.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_080436_0000 - Cloud - Cloud222.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0005 - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0006 - Cloud.ply'

# ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0007 - Cloud222-newRT3.ply'
# ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0007 - Cloud222-newRT2.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/Road_Reference - Cloud3333 - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/Road_Reference - Cloud2222 - Cloud.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_084032_0000 - Cloud444.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_084032_0000 - Cloud555.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0005 - Cloud - Cloud222.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0006 - Cloud - Cloud.ply'


ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0005 - Cloud - Cloud.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0006 - Cloud - Cloud222.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0005 - Cloud - Cloud222.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_075026_0006 - Cloud - Cloud222.ply'

ply_a = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_084032_0000 - Cloud444.ply'
ply_b = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/231024_084032_0000 - Cloud333.ply'









"""## Utils"""


def best_fit_transform(A, B):
    # get number of dimensions
    m = A.shape[1]

    # translate points to their centroids
    centroid_A = np.mean(A, axis=0)
    centroid_B = np.mean(B, axis=0)
    AA = A - centroid_A
    BB = B - centroid_B

    # rotation matrix
    H = np.dot(AA.T, BB)  # covariance matrix
    U, S, Vt = np.linalg.svd(H)
    R = np.dot(Vt.T, U.T)

    # special reflection case
    if np.linalg.det(R) < 0:
        Vt[m - 1, :] *= -1
        R = np.dot(Vt.T, U.T)

    # R x A + t = B
    # translation
    t = centroid_B.T - np.dot(R, centroid_A.T)

    # homogeneous transformation
    T = np.identity(m + 1)
    T[:m, :m] = R
    T[:m, m] = t

    return T, R, t


def nearest_neighbor(src, dst):
    neigh = NearestNeighbors(n_neighbors=1)
    neigh.fit(dst)
    distances, indices = neigh.kneighbors(src, return_distance=True)
    return distances.ravel(), indices.ravel()


def icp(A, B, init_pose=None, max_iterations=1000, tolerance=0.001):
    # get number of dimensions
    m = A.shape[1]

    # make points homogeneous, copy them to maintain the originals
    src = np.ones((m + 1, A.shape[0]))
    dst = np.ones((m + 1, B.shape[0]))
    src[:m, :] = np.copy(A.T)
    dst[:m, :] = np.copy(B.T)

    # apply the initial pose estimation
    if init_pose is not None:
        src = np.dot(init_pose, src)

    prev_error = 0

    for i in range(max_iterations):
        # find the nearest neighbors between the current source and destination points
        distances, indices = nearest_neighbor(src[:m, :].T, dst[:m, :].T)

        # compute the transformation between the current source and nearest destination points
        T, _, _ = best_fit_transform(src[:m, :].T, dst[:m, indices].T)

        # update the current source
        src = np.dot(T, src)

        # check error
        mean_error = np.mean(distances)
        print("mean_error and prev_error:", mean_error, prev_error)
        if np.abs(prev_error - mean_error) < tolerance:
            break
        prev_error = mean_error

    # calculate final transformation
    T, _, _ = best_fit_transform(A, src[:m, :].T)

    return T, distances, i




pcd_a = o3d.io.read_point_cloud(ply_a)
pcd_b = o3d.io.read_point_cloud(ply_b)


def draw_geometries(geometries):
    graph_objects = []

    for geometry in geometries:
        geometry_type = geometry.get_geometry_type()

        if geometry_type == o3d.geometry.Geometry.Type.PointCloud:
            points = np.asarray(geometry.points)
            colors = None
            if geometry.has_colors():
                colors = np.asarray(geometry.colors)
            elif geometry.has_normals():
                colors = (0.5, 0.5, 0.5) + np.asarray(geometry.normals) * 0.5
            else:
                geometry.paint_uniform_color((1.0, 0.0, 0.0))
                colors = np.asarray(geometry.colors)

            scatter_3d = go.Scatter3d(x=points[:, 0], y=points[:, 1], z=points[:, 2], mode='markers',
                                      marker=dict(size=1, color=colors))
            graph_objects.append(scatter_3d)

        if geometry_type == o3d.geometry.Geometry.Type.TriangleMesh:
            triangles = np.asarray(geometry.triangles)
            vertices = np.asarray(geometry.vertices)
            colors = None
            if geometry.has_triangle_normals():
                colors = (0.5, 0.5, 0.5) + np.asarray(geometry.triangle_normals) * 0.5
                colors = tuple(map(tuple, colors))
            else:
                colors = (1.0, 0.0, 0.0)

            mesh_3d = go.Mesh3d(x=vertices[:, 0], y=vertices[:, 1], z=vertices[:, 2], i=triangles[:, 0],
                                j=triangles[:, 1], k=triangles[:, 2], facecolor=colors, opacity=0.50)
            graph_objects.append(mesh_3d)

    fig = go.Figure(
        data=graph_objects,
        layout=dict(
            scene=dict(
                xaxis=dict(visible=False),
                yaxis=dict(visible=False),
                zaxis=dict(visible=False)
            )
        )
    )
    fig.show()


def rotation_matrix(axis, theta):
    axis = axis / np.sqrt(np.dot(axis, axis))
    a = np.cos(theta / 2.)
    b, c, d = -axis * np.sin(theta / 2.)

    return np.array([[a * a + b * b - c * c - d * d, 2 * (b * c - a * d), 2 * (b * d + a * c)],
                     [2 * (b * c + a * d), a * a + c * c - b * b - d * d, 2 * (c * d - a * b)],
                     [2 * (b * d - a * c), 2 * (c * d + a * b), a * a + d * d - b * b - c * c]])


from sklearn.metrics import mean_squared_error


def get_metrics(T, R, t):
    R_measure = T[:3, :3]
    T_measure = T[:3, 3]
    eul_measure = rot2eul(R_measure)
    eul_def = rot2eul(R)
    ang_dist = np.linalg.norm(eul_def - eul_measure)
    mse_translation = mean_squared_error(T_measure, t)
    return ang_dist, mse_translation


def rot2eul(R):
    beta = -np.arcsin(R[2, 0])
    alpha = np.arctan2(R[2, 1] / np.cos(beta), R[2, 2] / np.cos(beta))
    gamma = np.arctan2(R[1, 0] / np.cos(beta), R[0, 0] / np.cos(beta))
    return np.array((alpha, beta, gamma))


dim = 3  # number of dimensions of the points
noise_sigma = .01  # standard deviation error to be added
translation = .4  # max translation of the test set
rotation = .4
N = 10  # number of random points in the dataset


def pcd_changes(pcd, translation):
    new_pcd = copy.deepcopy(pcd)

    # Translate
    new_pcd = new_pcd.translate(translation)

    # Rotate
    R = rotation_matrix(np.random.rand(dim), np.random.rand() * rotation)
    new_pcd.rotate(R, center=(0, 0, 0))

    # Add noise
    new_pcd_points = np.asarray(new_pcd.points)
    new_pcd_points += np.random.randn(new_pcd_points.shape[0], new_pcd_points.shape[1]) * noise_sigma
    new_pcd.points = o3d.utility.Vector3dVector(new_pcd_points)

    return new_pcd, R


def my_print(header, x):
    print(f"{header}:\n")
    try:
        for row in x:
            print(' '.join(map(lambda x: "{:.3f}\t".format(x), row)))
    except:
        print(np.array2string(x, formatter={'float_kind': lambda x: "%.2f" % x}))





# 定义一个函数，用于加载ply文件并转换为open3d的点云格式
def load_las_file(file_name):
    pcd = o3d.io.read_point_cloud(file_name, format='ply')

    return pcd

def load_las_file_reallas(file_name):
    pcd = o3d.io.read_point_cloud(file_name, format='las')
    return pcd

# 定义一个函数，用于执行ICP匹配
def execute_icp(source_pcd, target_pcd, threshold=0.02, trans_init=[0, 0, 0, 0, 0, 0]):
    reg_p2p = o3d.pipelines.registration.registration_icp(
        source_pcd, target_pcd, threshold, trans_init,
        o3d.pipelines.registration.TransformationEstimationPointToPoint())
    return reg_p2p



"""## Visualization

### Original
"""

# o3d.visualization.draw_geometries = draw_geometries  # replace function
o3d.visualization.draw_geometries([pcd_a + pcd_b])

"""### After transformation"""

# pcd_b_changed, R = pcd_changes(pcd_b, [0.05, 0.05, 0.05])
pcd_b_changed = pcd_b

# o3d.visualization.draw_geometries = draw_geometries  # replace function
# o3d.visualization.draw_geometries([pcd_a + pcd_b_changed])

"""## Algorithms

### ICP
"""

# start = time.time()
# T, distances, iterations = icp(np.asarray(pcd_b_changed.points), np.asarray(pcd_a.points), tolerance=0.000001)
# print(time.time() - start)
# print(f"distances - {distances}")
# print(f"iterations - {iterations}")
#
# pcd_b_icp = copy.deepcopy(pcd_b_changed).transform(T)

# save_path = r'C:\Users\pc\Desktop\test3\lidar_camera_calibration_point_to_plane-master/data/dataset/data/01-pcd_b_icp-222222.ply'
# write_result = o3d.io.write_point_cloud(save_path, pcd_b_icp, format='ply')

# o3d.visualization.draw_geometries = draw_geometries  # replace function
# o3d.visualization.draw_geometries([pcd_a + pcd_b_icp])
# o3d.visualization.draw_geometries([pcd_a + pcd_b_icp], window_name="[pcd_a + pcd_b_icp]", width=880, height=1290)
# o3d.visualization.draw_geometries([pcd_a + pcd_b_icp], window_name="pcd_a + pcd_b_icXXX", width=1900, height=1000)

# """### Tr-ICP"""
#
# start = time.time()
# T, distances, iterations = tr_icp(np.asarray(pcd_b_changed.points), np.asarray(pcd_a.points), tolerance=0.000001)
# print(time.time() - start)
# print(f"distances - {distances}")
# print(f"iterations - {iterations}")
#
# pcd_b_tricp = copy.deepcopy(pcd_b_changed).transform(T)
#
# # o3d.visualization.draw_geometries = draw_geometries  # replace function
# # o3d.visualization.draw_geometries([pcd_a + pcd_b_tricp])
# # o3d.visualization.draw_geometries([pcd_a + pcd_b_tricp], window_name="[pcd_a + pcd_b_tricp]", width=880, height=1290)
# o3d.visualization.draw_geometries([pcd_a + pcd_b_tricp], window_name="pcd_a + pcd_b_tricXXX", width=1900, height=1000)






# # 设置工作目录到包含las文件的目录
# # 请根据实际情况修改下面的路径
# work_dir = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files"
#
# os.chdir(work_dir)
#
# # 获取所有las文件
# # las_files = [f for f in os.listdir(work_dir) if f.endswith('.las')]
# las_files = [f for f in os.listdir(work_dir) if f.endswith('.ply')]
#
# # 对文件进行排序，确保它们是按顺序处理的
# las_files.sort()


# def downsample_points(points, ratio=0.1):
#     """
#     对点云数据进行抽稀，保留原始数据量的ratio比例。
#     :param points: numpy数组，形状为(N, 3)，其中N是点的总数，每行代表一个点的坐标(x, y, z)。
#     :param ratio: 抽稀比例，例如0.1表示保留10%的数据。
#     :return: 抽稀后的点云数据。
#     """
#     # 计算需要保留的点数
#     num_points_to_keep = int(points.shape[0] * ratio)
#     # 随机选择点
#     indices = np.random.choice(points.shape[0], num_points_to_keep, replace=False)
#     # 根据索引选择点
#     downsampled_points = points[indices]
#
#     return downsampled_points




# ////////////////////////////////////////////
# 以下是保存抽稀并保存las文件

def downsample_points(points, ratio=0.1):
    """
    对点云数据进行抽稀，保留原始数据量的ratio比例。
    :param points: numpy数组，形状为(N, 3)，其中N是点的总数，每行代表一个点的坐标(x, y, z)。
    :param ratio: 抽稀比例，例如0.1表示保留10%的数据。
    :return: 抽稀后的点云数据。
    """
    num_points_to_keep = int(points.shape[0] * ratio)
    indices = np.random.choice(points.shape[0], num_points_to_keep, replace=False)
    downsampled_points = points[indices]
    return downsampled_points

# def load_las_file222(file_name):
#     with laspy.open(file_name) as las_file:
#         header = las_file.header
#         points = np.vstack((las_file.x, las_file.y, las_file.z)).transpose()
#     return points, header

# def load_las_file222(file_name):
#     with laspy.open(file_name) as las_file:
#         # 使用 las_file.points 获取所有点的坐标
#         points = np.vstack((las_file.points[:, 0], las_file.points[:, 1], las_file.points[:, 2])).transpose()
#     return points
def read_las_file222(file_path):
    las = laspy.read(file_path)
    points = np.vstack((las.x, las.y, las.z)).transpose()
    return points

def save_las_file222(points, output_file_path):
    header = laspy.LasHeader(point_format=3)
    outfile = laspy.LasData(header)
    outfile.x = points[:, 0]
    outfile.y = points[:, 1]
    outfile.z = points[:, 2]
    outfile.write(output_file_path)

# def save_las_file(points, header, file_name):
#     with laspy.open(file_name, mode='w', header=header) as las_file:
#         las_file.x = points[:, 0]
#         las_file.y = points[:, 1]
#         las_file.z = points[:, 2]


def downsample_points(points, ratio):
    """
    对点云数据进行抽稀处理。
    """
    # 获取点的数量
    n_points = points.shape[0]
    # 计算需要保留的点的数量
    n_keep = int(n_points * ratio)
    # 使用KDTree进行最近邻搜索
    tree = KDTree(points)
    # 找到每个点的最近邻点
    _, indices = tree.query(points, k=2)
    # 选择每个点的最近邻点作为保留的点
    keep_indices = np.zeros(n_points, dtype=bool)
    keep_indices[indices[:, 1]] = True
    # 从原始点云中选择保留的点
    downsampled_points = points[keep_indices]
    return downsampled_points

def denoise_points_nearbased(points, threshold, neighborhood_size):
    """
    使用基于邻域的去噪算法对点云数据进行去噪。
    """
    # 使用KDTree进行最近邻搜索
    tree = KDTree(points)
    # 计算每个点的邻域平均值
    distances, indices = tree.query(points, k=neighborhood_size + 1)
    neighborhood_means = np.mean(points[indices[:, 1:neighborhood_size+1], :], axis=1)
    # 计算每个点与邻域平均值之间的差值
    differences = points - neighborhood_means[:, np.newaxis, :]
    # 计算差值的欧氏距离
    distances = np.sqrt(np.sum(differences**2, axis=2))
    # 判断点是否为噪声点
    is_noise = distances > threshold
    # 对非噪声点进行插值处理
    denoised_points = np.zeros_like(points)
    for i in range(points.shape[0]):
        if not is_noise[i]:
            denoised_points[i] = points[i]
        else:
            # 找到最近的非噪声点并进行插值
            nearest_non_noise_index = np.where(is_noise[i] == False)[0][0]
            denoised_points[i] = (points[i] * nearest_non_noise_index + points[nearest_non_noise_index] * (is_noise[i].sum() - nearest_non_noise_index)) / (is_noise[i].sum())
    return denoised_points


def process_las_files_noise_reduction(input_folder, output_folder, downsample_ratio=0.1, noise_threshold=0.1, neighborhood_size=10):
    # 确保输出文件夹存在
    os.makedirs(output_folder, exist_ok=True)

    # 获取所有las文件
    las_files = [f for f in os.listdir(input_folder) if f.endswith('.las')]

    # 对文件进行排序，确保它们是按顺序处理的
    las_files.sort()

    # 遍历文件列表，执行抽稀和去噪操作
    for las_file in las_files:
        input_path = os.path.join(input_folder, las_file)
        output_path = os.path.join(output_folder, las_file)

        # 读取las文件
        points = read_las_file222(input_path)

        # 抽稀点云数据
        downsampled_points = downsample_points(points, ratio=downsample_ratio)

        # 去噪点云数据
        denoised_points = denoise_points_nearbased(downsampled_points, threshold=noise_threshold, neighborhood_size=neighborhood_size)

        save_path = f"{output_path}_after_denoise.las"
        # 保存las文件
        save_las_file222(denoised_points, save_path)

        print(f"Denoised points number: {len(denoised_points)}")
        print(f"Processed and saved: {save_path}")


def process_las_files_duplicate_pointcloud(batch_data, downsample_ratio=0.5):
    """
    对批量点云数据进行抽稀处理并去除重复点。
    :param batch_data: 一个包含输入和输出文件夹路径的字典，格式如下：
                       {
                           'input_folder': '输入文件夹路径',
                           'output_folder': '输出文件夹路径'
                       }
    :param downsample_ratio: 抽稀比例，默认为0.1
    """
    # 确保输出文件夹存在
    os.makedirs(batch_data['output_folder'], exist_ok=True)

    # 获取所有las文件
    las_files = [f for f in os.listdir(batch_data['input_folder']) if f.endswith('.las')]

    # 对文件进行排序，确保它们是按顺序处理的
    las_files.sort()

    # 遍历文件列表，执行抽稀和去重操作
    for las_file in las_files:
        input_path = os.path.join(batch_data['input_folder'], las_file)
        output_path = os.path.join(batch_data['output_folder'], las_file)

        # 读取las文件
        points = read_las_file222(input_path)

        # 去除重复点
        unique_points = remove_duplicate_points(points)

        # 抽稀点云数据
        downsampled_points = downsample_points(unique_points, ratio=downsample_ratio)

        save_path = f"{output_path}_after_downsample.las"
        # 保存las文件
        save_las_file222(downsampled_points, save_path)

        print(f"Downsampled points number: {len(downsampled_points)}")
        print(f"Processed and saved: {save_path}")

def remove_duplicate_points(points):
    """
    去除点云中的重复点。
    :param points: 点云数据，格式为numpy数组，每行代表一个点，每一列代表一个坐标轴。
    :return: 去除重复点后的点云数据。
    """
    # 将点云数据转换为numpy数组
    points_array = np.array(points)

    # 使用numpy的unique函数去除重复点
    _, unique_indices = np.unique(points_array, return_index=True, axis=0)
    unique_points = points_array[unique_indices]

    return unique_points


def read_las_file222_3d_overlap(file_path):
    # 使用 laspy 库读取 LAS 文件
    las = laspy.read(file_path)

    # 获取点云数据
    points = las.points

    # 计算边界框
    min_x = min(points.x)
    min_y = min(points.y)
    min_z = min(points.z)
    max_x = max(points.x)
    max_y = max(points.y)
    max_z = max(points.z)

    # 返回点云数据和边界框
    return points, (min_x, min_y, min_z, max_x, max_y, max_z)

def calculate_3d_overlap(box1, box2, overlap_ratio_threshold):
    # 计算两个边界框之间的重叠度，并判断是否超过阈值
    min_x1, min_y1, min_z1, max_x1, max_y1, max_z1 = box1
    min_x2, min_y2, min_z2, max_x2, max_y2, max_z2 = box2

    # 计算重叠区域
    overlap_x = max(0, min(max_x1, max_x2) - max(min_x1, min_x2))
    overlap_y = max(0, min(max_y1, max_y2) - max(min_y1, min_y2))
    overlap_z = max(0, min(max_z1, max_z2) - max(min_z1, min_z2))

    # 计算重叠体积
    overlap_volume = overlap_x * overlap_y * overlap_z

    # 计算两个边界框的体积
    volume1 = (max_x1 - min_x1) * (max_y1 - min_y1) * (max_z1 - min_z1)
    volume2 = (max_x2 - min_x2) * (max_y2 - min_y2) * (max_z2 - min_z2)

    # 计算重叠度
    overlap_ratio = overlap_volume / (volume1 + volume2 - overlap_volume)

    return overlap_ratio >= overlap_ratio_threshold


def process_las_files_3d_overlap(input_folder, output_folder, threeD_overlap_ratio_threshold=0.1):
    os.makedirs(output_folder, exist_ok=True)
    las_files = [f for f in os.listdir(input_folder) if f.endswith('.las')]
    las_files.sort()

    # 存储所有点云的边界框
    bounding_boxes = []
    for las_file in las_files:
        input_path = os.path.join(input_folder, las_file)
        points, bounding_box = read_las_file222_3d_overlap(input_path)
        bounding_boxes.append(bounding_box)

    # 检测重叠的点云对
    overlapping_pairs = []
    for i in range(len(las_files)):
        for j in range(i + 1, len(las_files)):
            if calculate_3d_overlap(bounding_boxes[i], bounding_boxes[j], threeD_overlap_ratio_threshold):
                overlapping_pairs.append((las_files[i], las_files[j]))

    # 输出重叠的3D点云对
    for pair in overlapping_pairs:
        print(f"Overlapping pair detected: {pair[0]} and {pair[1]}")


def process_las_files(input_folder, output_folder, ratio=0.1):
    # 确保输出文件夹存在
    os.makedirs(output_folder, exist_ok=True)

    # 获取所有las文件
    las_files = [f for f in os.listdir(input_folder) if f.endswith('.las')]

    # 对文件进行排序，确保它们是按顺序处理的
    las_files.sort()

    # 遍历文件列表，执行抽稀操作
    for las_file in las_files:
        input_path = os.path.join(input_folder, las_file)
        output_path = os.path.join(output_folder, las_file)

        # 读取las文件
        # points, header = load_las_file222(input_path)
        points = read_las_file222(input_path)

        # 抽稀点云数据
        downsampled_points = downsample_points(points, ratio=ratio)

        save_path = f"{output_path}_after_downsample.las"
        # 保存las文件
        # save_las_file(downsampled_points, header, output_path)
        save_las_file222(downsampled_points, save_path)

        print(f"downsampled_points number: {len(downsampled_points)}")
        print(f"Processed and saved: {output_path}")


def transform_destination_point_cloud(points, transform_matrix):
    """  
    变换点云数据。  
      参数:  
    - points: NumPy数组，形状为(N, 3)，其中N是点的数量，每个点由(x, y, z)坐标表示。  
    - transform_matrix: NumPy数组，形状为(4, 4)，表示变换矩阵。  
      返回:  
    - transformed_points: 变换后的点云数据，形状为(N, 3)。  
    """  
    # 增加一列1以进行齐次坐标变换  
    points_homogeneous = np.hstack((points, np.ones((points.shape[0], 1))))  
    # 执行矩阵乘法  
    transformed_points_homogeneous = np.dot(points_homogeneous, transform_matrix.T)  
    # 移除最后一列以恢复非齐次坐标  
    transformed_points = transformed_points_homogeneous[:, :3]  
    return transformed_points  

# 示例数据  
# 注意：这里的目标点云数据和变换矩阵只是示例，实际应用中需要根据具体情况确定  
destination_points = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])  

transform_destination_matrix = np.array([  
    [1, 0, 0, 2],  # 旋转部分（这里仅作为示例，实际旋转会更复杂）和x方向平移2  
    [0, 1, 0, 3],  # y方向平移3  
    [0, 0, 1, 4],  # z方向平移4  
    [0, 0, 0, 1]   # 齐次坐标的缩放部分，通常为1  
])   


if __name__ == "__main__":
    input_folder = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds"
    output_folder = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds"
    # output_folder = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds_downsample"
    # 批量化点-点等间隔采样处理
    process_las_files(input_folder, output_folder)
    # 批量化点-点等间隔采样, 且基于领域去噪处理
    # process_las_files('input_folder', 'output_folder', downsample_ratio=0.1, noise_threshold=0.2, neighborhood_size=15)

    # # 3维空间中的点云重叠度, 默认超过20%的都可以作为粗匹配和精匹配的有效数据. 少数低于20%的数据建议只用精匹配处理.
    # process_las_files_3d_overlap( r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds/input_folder", r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/out_floder", 3d_overlap_ratio_threshold=0.2)

    # # 调用目标点云变换函数进行变换  
    # transformed_destination_points = transform_destination_point_cloud(destination_points, transform_destination_matrix)  





# ////////////////////////////////////////////
# 以下是保存抽稀并保存ply文件

# def downsample_points(points, ratio=0.1):
#     """
#     对点云数据进行抽稀，保留原始数据量的ratio比例。
#     :param points: numpy数组，形状为(N, 3)，其中N是点的总数，每行代表一个点的坐标(x, y, z)。
#     :param ratio: 抽稀比例，例如0.1表示保留10%的数据。
#     :return: 抽稀后的点云数据。
#     """
#     num_points_to_keep = int(points.shape[0] * ratio)
#     indices = np.random.choice(points.shape[0], num_points_to_keep, replace=False)
#     downsampled_points = points[indices]
#     return downsampled_points
#
#
# work_dir = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds"
#
# os.chdir(work_dir)
# # 获取所有las文件
# # las_files = [f for f in os.listdir(work_dir) if f.endswith('.las')]
# las_files = [f for f in os.listdir(work_dir) if f.endswith('.ply')]
#
# # 对文件进行排序，确保它们是按顺序处理的
# las_files.sort()
#
# def process_las_files(input_folder, output_folder, ratio=0.1):
#     # 确保输出文件夹存在
#     os.makedirs(output_folder, exist_ok=True)
#
#     # las_files = [f for f in os.listdir(work_dir) if f.endswith('.las')]
#     las_files = [f for f in os.listdir(work_dir) if f.endswith('.ply')]
#
#     # 对文件进行排序，确保它们是按顺序处理的
#     las_files.sort()
#
#
#     # 遍历文件列表，两两配对执行ICP匹配
#     for i in range(len(las_files) ):
#         # source_pcd = load_las_file_reallas(las_files[i])
#         source_pcd = load_las_file(las_files[i])
#
#         # 获取点云的points属性
#         points = np.asarray(source_pcd.points)
#
#         # 抽稀点云数据
#         downsampled_points = downsample_points(points, ratio=ratio)
#
#         # save_path = f"{las_files[i]}_after_downsample.las"
#         save_path = f"{las_files[i]}_after_downsample.ply"
#         # 将抽稀后的点云数据保存到新的las文件
#         # np.savetxt(save_path, downsampled_points, fmt='%.6f')
#         # write_result = o3d.io.write_point_cloud(save_path, reg_p2p_1_reverse, format='ply')
#
#         new_pcd = o3d.geometry.PointCloud()
#         new_pcd.points = o3d.utility.Vector3dVector(downsampled_points)
#         # new_pcd.colors = pcd.colors  # 如果有颜色信息，也进行复制
#         write_result = o3d.io.write_point_cloud(save_path, new_pcd)
#         print(f"write succeed222 - {write_result}")
#
# if __name__ == "__main__":
#     input_folder = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds"
#     output_folder = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds_downsample"
#     # input_folder = 'test_save_las_files_testds'
#     # output_folder = 'test_save_las_files_testds_downsample'
#     process_las_files(input_folder, output_folder)










# work_dir = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds"
#
# os.chdir(work_dir)
# # 获取所有las文件
# # las_files = [f for f in os.listdir(work_dir) if f.endswith('.las')]
# las_files = [f for f in os.listdir(work_dir) if f.endswith('.ply')]
#
# # 对文件进行排序，确保它们是按顺序处理的
# las_files.sort()
#
# def process_las_files(input_folder, output_folder, ratio=0.1):
#     # 确保输出文件夹存在
#     os.makedirs(output_folder, exist_ok=True)
#
#     # las_files = [f for f in os.listdir(work_dir) if f.endswith('.las')]
#     las_files = [f for f in os.listdir(work_dir) if f.endswith('.ply')]
#
#     # 对文件进行排序，确保它们是按顺序处理的
#     las_files.sort()
#
#
#     # 遍历文件列表，两两配对执行ICP匹配
#     for i in range(len(las_files) ):
#         # source_pcd = load_las_file_reallas(las_files[i])
#         source_pcd = load_las_file(las_files[i])
#
#         # 获取点云的points属性
#         points = np.asarray(source_pcd.points)
#
#         # 抽稀点云数据
#         downsampled_points = downsample_points(points, ratio=ratio)
#
#         # save_path = f"{las_files[i]}_after_downsample.las"
#         save_path = f"{las_files[i]}_after_downsample.ply"
#         # 将抽稀后的点云数据保存到新的las文件
#         # np.savetxt(save_path, downsampled_points, fmt='%.6f')
#         # write_result = o3d.io.write_point_cloud(save_path, reg_p2p_1_reverse, format='ply')
#
#         new_pcd = o3d.geometry.PointCloud()
#         new_pcd.points = o3d.utility.Vector3dVector(downsampled_points)
#         # new_pcd.colors = pcd.colors  # 如果有颜色信息，也进行复制
#         write_result = o3d.io.write_point_cloud(save_path, new_pcd)
#         print(f"write succeed222 - {write_result}")
#
# if __name__ == "__main__":
#     input_folder = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds"
#     output_folder = r"C:/Users/pc/Desktop/test3/lidar_camera_calibration_point_to_plane-master/data/dataset/data/test_save_las_files_testds_downsample"
#     # input_folder = 'test_save_las_files_testds'
#     # output_folder = 'test_save_las_files_testds_downsample'
#     process_las_files(input_folder, output_folder)










# """## Reports"""
# t_vectors = [[0.01, 0.02, 0.03], [0.04, 0.05, 0.06], [0.07, 0.08, 0.09], [0.03, 0.05, 0.01], [0.06, 0.04, 0.01]]



















